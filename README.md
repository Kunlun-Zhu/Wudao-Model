# WuDao-Model

“悟道”项目现有7个开源模型成果，模型参数文件需到[悟道平台](https://resource.wudaoai.cn/home)进行下载申请，该项目仓库提供模型介绍及源代码。

### 图文类

* **[CogView](https://git.openi.org.cn/BAAI/WuDao-Model/src/branch/master/CogView)**

  CogView参数量为40亿，模型可实现文本生成图像，经过微调后可实现国画、油画、水彩画、轮廓画等图像生成。目前在公认MS COCO文生图任务上取得了超过OpenAI DALL·E的成绩，获得世界第一。

* **[BriVL](https://git.openi.org.cn/BAAI/WuDao-Model/src/branch/master/BriVL)**

  BriVL (Bridging Vision and Language Model) 是首个中文通用图文多模态大规模预训练模型。BriVL模型在图文检索任务上有着优异的效果，超过了同期其他常见的多模态预训练模型（例如UNITER、CLIP）。

### 文本类

* **[GLM](https://git.openi.org.cn/BAAI/WuDao-Model/src/branch/master/GLM)**

  GLM是以英文为核心的预训练语言模型系列，基于新的预训练范式实现单一模型在语言理解和生成任务方面取得了最佳结果，并且超过了在相同数据量进行训练的常见预训练模型（例如BERT，RoBERTa和T5），目前已开源1.1亿、3.35亿、4.10亿、5.15亿、100亿参数规模的模型。
  
* **[CPM](https://git.openi.org.cn/BAAI/WuDao-Model/src/branch/master/CPM)**

  CPM系列模型是兼顾理解与生成能力的预训练语言模型系列，涵盖中文、中英双语多类模型，目前已开源26亿、110亿和1980亿参数规模的模型。
  
* **[Transformer-XL](https://git.openi.org.cn/BAAI/WuDao-Model/src/branch/master/Transformer-XL)**

  Transformer-XL是以中文为核心的预训练语言生成模型，参数规模为29亿，目前可支持包括文章生成、智能作诗、评论/摘要生成等主流NLG任务。

* **[EVA](https://git.openi.org.cn/BAAI/WuDao-Model/src/branch/master/EVA)**

  EVA是一个开放领域的中文对话预训练模型，是目前最大的汉语对话模型，参数量达到28亿，并且在包括不同领域14亿汉语的悟道对话数据集（WDC）上进行预训练。

* **[Lawformer](https://git.openi.org.cn/BAAI/WuDao-Model/src/branch/master/Lawformer)**

  Lawformer是世界首创法律领域长文本中文预训练模型，参数规模达到1亿。

### 蛋白质类

* **[ProtTrans](https://git.openi.org.cn/BAAI/WuDao-Model/src/branch/master/ProtTrans)**

  ProtTrans是国内最大的蛋白质预训练模型，参数总量达到30亿。
